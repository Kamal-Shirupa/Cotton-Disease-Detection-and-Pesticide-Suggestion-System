# -*- coding: utf-8 -*-
"""Cotton-Disease-Detection-and-Pesticide-Suggestion-System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J_LTsWD7rRbvfEGfPBAaRUbxGjeea0CO
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.preprocessing import LabelBinarizer

# === STEP 1: Paths ===
base_path = "/kaggle/input/cotton/dataset"
train_dir = os.path.join(base_path, "cotton disease/train")
test_dir = os.path.join(base_path, "cotton disease/test")
predict_dir = os.path.join(base_path, "predictions")
pesticide_csv = os.path.join(base_path, "cotton_pesticide.csv")

# === STEP 2: Load Data ===
img_height, img_width = 128, 128
batch_size = 32

train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode="categorical"
)

val_gen = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode="categorical"
)

# Print classes for debug
class_labels = list(train_gen.class_indices.keys())
print("Class Labels:", class_labels)

# === STEP 3: Build Simple CNN ===
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(img_height, img_width, 3)),
    MaxPooling2D(),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(),
    Flatten(),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dense(len(class_labels), activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# === STEP 4: Train Model ===
callbacks = [
    EarlyStopping(patience=5, restore_best_weights=True),
    ModelCheckpoint("best_model.keras", save_best_only=True)
]

history = model.fit(train_gen, epochs=10, validation_data=val_gen, callbacks=callbacks)

# === STEP 5: Load Pesticide Dataset ===
pesticide_df = pd.read_csv(pesticide_csv)
pesticide_df.columns = [col.strip().lower().replace("\n", " ").replace("  ", " ") for col in pesticide_df.columns]
pesticide_df['disease'] = pesticide_df['disease'].str.strip().str.lower()

# === STEP 6: Pesticide Recommendation Function ===
def recommend_pesticide(disease_name):
    disease_name = disease_name.lower().strip()
    match = pesticide_df[pesticide_df['disease'] == disease_name]
    if not match.empty:
        row = match.iloc[0]
        return {
            "Description": row.get('description', 'N/A'),
            "Pesticide (Small Region)": row.get('pesticide (small region)', 'N/A'),
            "Dosage (Small Region)": row.get('dosage (small region)', 'N/A'),
            "Pesticide (Large Region)": row.get('pesticide (large region)', 'N/A'),
            "Dosage (Large Region)": row.get('dosage (large region)', 'N/A'),
            "Organic Method": row.get('organic method', 'N/A')
        }
    else:
        return {"Note": "No pesticide data found for this disease."}

# === STEP 7: Predict + Recommend Function ===
def predict_and_recommend(image_path):
    img = load_img(image_path, target_size=(img_height, img_width))
    img_array = img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    prediction = model.predict(img_array)
    predicted_index = np.argmax(prediction)
    predicted_class = class_labels[predicted_index]

    print("Predicted Disease:", predicted_class)
    recommendation = recommend_pesticide(predicted_class)
    print("Pesticide Recommendation:")
    for k, v in recommendation.items():
        print(f"{k}: {v}")

# === STEP 8: Try an Example ===
predict_and_recommend(os.path.join(predict_dir, "cotton_d2.jpg"))

# Updated pesticide recommendation function with normalization
def normalize(text):
    return text.strip().lower().replace('_', ' ')

def recommend_pesticide(disease_name):
    disease_name = normalize(disease_name)
    pesticide_df['normalized_disease'] = pesticide_df['disease'].apply(normalize)

    match = pesticide_df[pesticide_df['normalized_disease'] == disease_name]
    if not match.empty:
        row = match.iloc[0]
        return {
            "Description": row.get('description', 'N/A'),
            "Pesticide (Small Region)": row.get('pesticide (small region)', 'N/A'),
            "Dosage (Small Region)": row.get('dosage (small region)', 'N/A'),
            "Pesticide (Large Region)": row.get('pesticide (large region)', 'N/A'),
            "Dosage (Large Region)": row.get('dosage (large region)', 'N/A'),
            "Organic Method": row.get('organic method', 'N/A')
        }
    else:
        return {"Note": "No pesticide data found for this disease."}

predict_and_recommend(os.path.join(predict_dir, "cotton_d2.jpg"))